# -*- coding: utf-8 -*-
"""ANN Komat Perbaikan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gOr7jcL-a5B4mbp-jW4owtIdiCIcvU7X
"""

!pip install tensorflow

import pandas as pd  # Untuk manipulasi data tabular
import numpy as np  # Untuk operasi numerik
import kagglehub  # Untuk mengunduh dataset dari Kaggle (pakai kagglehub)
import os  # Untuk operasi file/folder
import matplotlib.pyplot as plt  # Untuk visualisasi grafik

from sklearn.model_selection import train_test_split  # Untuk membagi data training dan testing
from sklearn.preprocessing import LabelEncoder  # Untuk mengubah label kategori menjadi angka
from sklearn.metrics import classification_report  # Untuk evaluasi model klasifikasi

from tensorflow.keras.preprocessing.text import Tokenizer  # Mengubah teks menjadi angka
from tensorflow.keras.preprocessing.sequence import pad_sequences  # Menyamakan panjang input teks
from tensorflow.keras.models import Sequential  # Model berurutan (layer satu per satu)
from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense, Dropout, Flatten  # Layer yang digunakan
from tensorflow.keras.callbacks import EarlyStopping  # Menghentikan training lebih awal jika model tidak membaik
from tensorflow.keras.utils import to_categorical  # Untuk mengubah label ke one-hot (tidak dipakai di sini)

# Download latest version
path = kagglehub.dataset_download("bhavikjikadara/emotions-dataset") # Unduh dataset dari KaggleHub

print("Path to dataset files:", path)

path = "/kaggle/input/emotions-dataset"  # Path ke folder dataset di Kaggle
for root, dirs, files in os.walk(path):  # Tampilkan semua file di folder tersebut
    print("üìÅ Folder:", root)
    for file in files:
        print("  üìÑ", file)

df = pd.read_csv(os.path.join(path, "emotions.csv")) # Baca file emotions.csv ke dalam DataFrame
file_path = os.path.join(path, "emotions.csv")
df = pd.read_csv(file_path)

# Label mapping (ubah angka ke teks)
label_map = { # Kamus untuk konversi label angka ke nama emosi
    0: 'sadness',
    1: 'joy',
    2: 'love',
    3: 'anger',
    4: 'fear',
    5: 'surprise'
}

# Ubah label numerik ke teks
df['label_text'] = df['label'].map(label_map) # Tambahkan kolom baru label_text berdasarkan mapping
print("\nLabel setelah konversi:\n", df['label_text'].value_counts()) # Hitung frekuensi tiap label

# Tampilkan hanya kolom text dan label_text
print(df[['text', 'label_text']].head())  # 5 data pertama

# Tampilkan jumlah data per label_text
print("\nJumlah data per label:")
print(df['label_text'].value_counts())

# Tokenisasi teks
tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')  # Tokenizer dengan 10.000 kata terbanyak, token OOV untuk kata asing
tokenizer.fit_on_texts(df['text'])  # Pelajari kata-kata dari teks
sequences = tokenizer.texts_to_sequences(df['text'])  # Ubah teks jadi urutan angka
X = pad_sequences(sequences, maxlen=100, padding='post')  # Ubah semua ke panjang 100 (padding di akhir)

# Encode label
le = LabelEncoder()  # Encoder label dari string ke angka
y = le.fit_transform(df['label'])  # Ubah label ke angka

#Split Data
X_train, X_test, y_train, y_test = train_test_split(  # Bagi data untuk training dan testing
    X, y,
    test_size=0.2,  # 20% untuk data uji
    random_state=42  # Agar hasil konsisten setiap dijalankan
)

print(le.classes_) # Lihat urutan kelas

len(df)

model = Sequential()  # Model bertipe sequential
model.add(Embedding(input_dim=10000, output_dim=64, input_length=100))  # Layer embedding dari kata ke vektor
model.add(GlobalAveragePooling1D())  # Rata-rata dari seluruh vektor
model.add(Dense(64, activation='relu'))  # Layer dense 64 neuron
model.add(Dropout(0.3))  # Dropout 30% untuk mencegah overfitting
model.add(Dense(32, activation='relu'))  # Layer dense lagi
model.add(Dense(len(le.classes_), activation='softmax'))  # Output sebanyak jumlah kelas, aktivasi softmax

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # Kompilasi model
model.build(input_shape=(None, 100))  # Tentukan bentuk input
model.summary()  # Tampilkan arsitektur model

early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)  # Berhenti kalau val_loss tidak membaik setelah 3 epoch

# Training
history = model.fit(
    X_train, y_train,
    epochs=20,  # Maksimum 20 epoch
    batch_size=32,  # Jumlah data per batch
    validation_data=(X_test, y_test),  # Validasi selama training
    callbacks=[early_stop],  # Gunakan early stopping
    verbose=2  # Tampilkan hasil training
)

# Evaluasi akurasi
loss, accuracy = model.evaluate(X_test, y_test)  # Evaluasi di data uji
print(f"\nüéØ Akurasi Uji: {accuracy * 100:.2f}%")  # Tampilkan akurasi

# Prediksi
y_pred = model.predict(X_test).argmax(axis=1)  # Prediksi kelas dari output softmax

#Classification Report
target_names = list(label_map.values())  # Daftar nama label
print("\nüìã Classification Report:")
print(classification_report(y_test, y_pred, target_names=target_names))  # Tampilkan precision, recall, f1-score

# Grafik akurasi/loss
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title('Akurasi')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Loss')
plt.legend()
plt.tight_layout()
plt.show()

# Konversi label angka ke bentuk teks
y_test_labels = le.inverse_transform(y_test)
y_pred_labels = le.inverse_transform(y_pred)

# Tampilkan contoh 10 prediksi
print("\nüîç Contoh Prediksi (10 data):")
for i in range(10):
    kalimat = tokenizer.sequences_to_texts([X_test[i]])[0]
    print(f"Teks: {kalimat}")
    print(f"üëâ Prediksi: {y_pred_labels[i]} | Asli: {y_test_labels[i]}")
    print("---")

label_dict = label_map  # Gunakan label_map sebagai label_dict

def prediksi_emosi(teks):
    """
    Fungsi untuk memprediksi emosi dari sebuah kalimat teks.
    Mengembalikan nama emosi dan indeks prediksi.
    """
    # Tokenisasi teks input
    seq = tokenizer.texts_to_sequences([teks])
    pad = pad_sequences(seq, maxlen=100, padding='post')  # Sesuaikan panjang input

    # Prediksi menggunakan model
    pred_index = model.predict(pad).argmax()

    # Ambil nama label
    label = label_dict.get(pred_index, "unknown")

    return f"Prediksi Emosi: {label})"

contoh_teks = "I am so happy and excited today!"
print(prediksi_emosi(contoh_teks))